### 一、Youtube

Youtube发表过4篇能够描述这些年YouTube推荐系统变化的论文。

#### 1. Video Suggestion and Discovery for YouTube: Taking Random Walks Through the View Graph

这篇文章从最基本的co-view概念入手，先讲了一个直观的概念 — — item-based collaborative filtering system。

作者在这篇文章里提出一种叫做Adsorption的学习框架，当我们有一个小的labeled数据集和一个很大的unlabeled数据集时，可以通做Adsorption将label从小的数据集推广到大数据集上。

一种Adsorption的方法就是进行Random Walk，将每一个顶点v的label发到相关联的邻居上，在每一次传递结束后，对顶点的label进行归一化。

这种Adsorption的方法可以用来做推荐系统。

一种做法是把user观看video的关系当做一张图，把用户喜欢看的视频当做label，然后进行random walk，将label推广到其他的视频上。

这篇文章最后的实验离线测试效果很好，后来Pinterest也采用random walk来生成related pin的候选集，能够很好的提高用户互动情况。

#### 2. The YouTube Video Recommendation System， 2010年

篇幅仅有短短的4页，但是包含了YouTube推荐系统的产品理念，数据处理，系统设计以及实验结果。

在主页上推荐视频和推荐一个视频的相关视频在需求上有一定的差异，主页上的推荐对内容的新鲜度，发散性以及用户近期行为的相关性要求比较高。



#### 3. Label Partitioning For Sublinear Ranking，2013年

这是YouTube开始转向采用embedding来进行视频推荐的基础，非常值得一读。



#### 4. Deep Neural Networks for YouTube Recommendations,2016年

本论文根据典型的两阶段信息检索的二分法（two-stage information retrieval dichotomy）分为两部分：

第一部分是Candidate Generation，用来从上千万上亿个视频中选择少数(几百，几千)个候选视频，然后通过第二部分ranking来对这些候选视频进行详细打分，得分最高的视频作为最终结果呈现给用户。![img](https://cdn-images-1.medium.com/max/1600/0*TjlA4qifK6Tp5Ep1.)

	在Candidate Generation的时候，这篇文章采用了word embedding的技巧来计算每一个视频的embedding；然后将视频的embedding，用户搜索问题的embedding分别计算average，再加入用户的性别，国家，年龄，视频质量等特征，采用两个完全相连的ReLU层和softmax函数来预测用户下一个看的视频是什么。

![img](https://cdn-images-1.medium.com/max/1600/0*qQmHT5ZknX97K-Wa.)

	推荐时可以采用最近邻搜索的解决方案，在上亿数据中找到用户最有可能观看的下一个视频。在最初读这篇文章的时候我就有一个问题，如何在上亿输出中找到最有可能的一个，在读了上一篇“Label Partitioning for Sublinear Ranking”后我感觉YouTube就是采用把中间层当做input space，进行最近邻搜索，然后衡量下一个可能看的视频的概率。
	
	尽管深度神经网络可以在很大程度上减少工程师的工作量，但是YouTube还是花了不少人力从视频中抽取更多有效的特征，包括预测视频的特征，预测视频和历史观看记录生成的crossing features，以及用户观看视频的时效特征。
	
	在最终实现时，YouTube推荐系统面临两大考验，

- **一方面是Freshness**，每小时都有很多新的视频上传，但是推荐算法偏向老的内容，这篇文章中提到用age作为一个特征进行训练，在最后推荐时设所有的内容age为0，有效的模拟了老内容引入的bias。
- **另一方面是训练时的噪音**，很多时候用户点击观看一个视频并不代表用户真的喜欢，满意这个内容，所以在最后选择训练样例时，加入了观看时长这一衡量标准。



### 二、Google News

#### 1. Google News Personalization: Scalable Online Collaborative Filtering， 2007年

	经典的CF有个巨大的问题，无论是user-based还是item-based，当你要算任意两个user或者两个item之间相似度的时候，计算量会非常巨大。因为CF的计算量直接取决于特征维数和user、item pairs的数目，而资讯类产品这两个数目都非常巨大：1）每个user、item的特征因为大多是曝光、点击等行为类特征，而资讯类产品这些行为发生的cost很小几乎可以忽略不计，导致维度往往比较高；2）资讯类产品的user数目和item数目都很大，这和一般领域往往只有一方比较大是不同的。Google这篇论文的核心就是将CF改造为支持大规模计算的方法。其原理也很简单：将用户事先分成群，再做user-based CF时实际变成了(user) cluster-based CF。这样在工程实现上就简化了很多，线上只需要记录每群用户喜欢什么（实际做法是用到了基于的内存key-value系统，key为资讯ID，而value则是资讯在用户群上的各种统计值）。一个用户来了之后，先找到其对应的群，再推荐这个群喜欢的资讯就好。而线下则借助Map-Reduce实现了MinHash、PLSI两种聚类分群算法，定时把最新分群结果推到线上。
	
	CF是一个依赖用户行为数据就可以work的算法，它不像其他基于内容推荐的算法对NLP能力要求很高。选择CF，则绕过了NLP这个拦路虎（有经验的人都知道，NLP是一个长期积累的过程，很难一开始就做到比较出色的程度）。



	结合前面总结的资讯推荐的挑战，可以看到该算法主要解决了可扩展性问题。我们也不难发现这个user cluster-based的算法也有一些明显的缺点：1）它不能解决新用户、新资讯的冷启动，因为没有行为数据来支撑CF运转；2）推荐精度不够高，没有做到真正的个性化。这是cluster-based CF算法本身的特点决定的；3）实时性不够。用户聚类不能做到快速更新，这导致了对用户最新兴趣把握有不及时的风险。这些问题在Google News的另一篇论文中得到了解决。

#### 2. Personalized News Recommendation Based on Click Behavior， 2010年

	这篇文章重点解决推荐精准性和新资讯的冷启动问题，文章想法也很朴素自然，主要是基于贝叶斯理论进行建模。他们假设用户兴趣有两个方面：个人不断变化的兴趣以及当前新闻热点。在具体建模之前，作者先基于历史数据进行了统计分析，验证了他们的假设，得到如下基本结论：用户的兴趣是随时间变化的，新闻热点也是随时间变化的。还有一个比较有趣的结论是不同地区同一时间的新闻热点是不一样的。
	
	总体来看，该算法是非常简洁自然的，它针对CF遗留的问题进行了很好的解决：1）引入新闻类别解决了新新闻的冷启动；2）引入用户兴趣解决了个性化和推荐精确度的问题。

### 三、Yahoo Today

#### 1. Personalized Recommendation on Dynamic Content Using Predictive Bilinear Models， 2009年

	重点解决资讯推荐里的冷启动问题。不同于上一篇google news的做法，这篇文章试图同时解决新用户和新资讯的冷启动。本文的基本假设：**用户画像能刻画用户的阅读兴趣，新闻的画像也可以表示新闻的点击率，而用户喜欢一条新闻的程度则取决于静态预测和动态预测两个方面，都是用feature-based learning方法来建模用户对资讯感兴趣的程度。**
	
	所以当一个新的用户到来时，第二项的特征是没有，相当于仅用用户的画像等静态特征来解决新用户的预测问题。当一个新资讯时，也是同样的道理。静态特征如搜集到的用户的年龄、性别、地域等基础属性，以及从其他途径获取的如在相似产品上的行为、其他场景上的历史信息等，还有资讯的类目、主题等。而动态特征如用户在Yahoo Today上的各种阅读、点击、评分以及加工出来的某条资讯、某类资讯分时间段的各种统计值等。有了预测分s，和真实的label (比如用户是否点击一个资讯r(i,j))做个比较就能得到机器学习训练时的反馈信息。本文优化目标是基于贝叶斯理论推导出来的最大化后验概率(maximum-a-posteriori, MAP)，而优化方法则采用熟知的梯度下降法(gradient-descent, GD)。

#### 2. A Contextual-Bandit Approach to Personalized News Article Recommendation， 2010年

	这篇文章基于传统的Explore-Exploit(EE)套路，大家可能比较熟悉的是为新item随机一部分流量让其曝光，得到一些反馈，然后模型才能对其有较好的建模能力，这是最naïve的EE策略。稍微高大上一点的做法则是upper confidence bound(UCB)策略: 假设有K个新item没有任何先验，每个item的回报也完全不知道。每个item的回报均值都有个置信区间，而随着试验次数增加，置信区间会变窄，对应的是最大置信边界向均值靠拢。如果每次投放时，我们选择置信区间上限最大的那个，则就是UCB策略。这个策略的原理也很好理解，说白了就是实现了两种期望的效果。：1）均值差不多时，每次优先给统计不那么充分的资讯多些曝光；2）均值有差异时，优先出效果好的。而yahoo这篇文章，则是对UCB进行了优化，因为UCB对item没有任何先验知识，而linUCB可以引入一些先验知识。比如你在推荐新闻时，可能发现娱乐类新闻天然比体育类新闻点击率高。如果能把这个信息作为先验知识考虑进EE策略中，就可以加速EE的效率。LinUCB假设每次曝光的回报是和Feature(user, item) 成linear关系的，然后使用model预估期望点击和置信区间来加速收敛。



### 四、美团

#### 1. 深度学习在美团推荐平台排序中的运用

https://tech.meituan.com/dl.html

推荐系统的策略主要分为召回和排序两个过程:

召回层：

- User-Based 协同过滤
- Model-Based 协同过滤
- Item-Based 协同过滤
- Query-Based
- Location-Based

排序层：每类召回策略都会召回一定的结果，这些结果去重后需要统一做排序。点评推荐排序的框架大致可以分为三块：

- 离线计算层：离线计算层主要包含了算法集合、算法引擎，负责数据的整合、特征的提取、模型的训练、以及线下的评估。
- 近线实时数据流：主要是对不同的用户流实施订阅、行为预测，并利用各种数据处理工具对原始日志进行清洗，处理成格式化的数据，落地到不同类型的存储系统中，供下游的算法和模型使用。
- 在线实时打分：根据用户所处的场景，提取出相对应的特征，并利用多种机器学习算法，对多策略召回的结果进行融合和打分重排。

![dw topic](https://tech.meituan.com/img/dpdl/p1.png)

	我们采用多种机器学习算法，并通过线下AUC、NDCG、Precision等指标来评估他们的表现。线下模型经过训练和评估后，如果在测试集有比较明显的提高，会将其上线进行线上AB测试。同时，我们也有多种维度的报表对模型进行数据上的支持。

评推荐系统的实现中，首先要确定应用场景的数据，美团的数据可以分为以下几类：

- 用户画像：性别、常驻地、价格偏好、Item偏好等。
- Item画像：包含了商户、外卖、团单等多种Item。其中商户特征包括：商户价格、商户好评数、商户地理位置等。外卖特征包括：外卖平均价格、外卖配送时间、外卖销量等。团单特征包括：团单适用人数、团单访购率等。
- 场景画像：用户当前所在地、时间、定位附近商圈、基于用户的上下文场景信息等。

常用的特征选择方法：

![dw topic](https://tech.meituan.com/img/dpdl/p33.png)

	因为不同特征之间的组合是非常有效的，并有很好的可解释性，比如我们将"商户是否在用户常驻地"、"用户是否在常驻地"以及"商户与用户当前距离"进行组合，再将数据进行离散化，通过组合特征，我们可以很好的抓住离散特征中的内在联系，为线性模型增加更多的非线性表述。

### 五、Google

#### 1. Wide & Deep Learning模型





### 六、美团

#### 1、深度学习在美团搜索广告排序的应用实践

https://tech.meituan.com/searchads_dnn.html

美团搜索广告业务囊括了关键词搜索、频道筛选等业务，覆盖了美食、休娱、酒店、丽人、结婚、亲子等200多种应用场景，用户需求具有多样性。同时O2O模式下存在地理位置、时间等独特的限制。
结合上述场景，我们抽取了以下几大类特征：

- 用户特征

  - 人口属性：用户年龄，性别，职业等。
  - 行为特征：对商户/商圈/品类的偏好（实时、历史），外卖偏好，活跃度等。
  - 建模特征：基于用户的行为序列建模产生的特征等。

- 商户特征

  - 属性特征：品类，城市，商圈，品牌，价格，促销，星级，评论等。
  - 统计特征：不同维度/时间粒度的统计特征等。
  - 图像特征：类别，建模特征等。
  - 业务特征：酒店房型等。

- Query特征

  - 分词，意图，与商户相似度，业务特征等。

- 上下文特征

  - 时间，距离，地理位置，请求品类，竞争情况等。
  - 广告曝光位次。


#### 2. 美团“猜你喜欢”深度学习排序模型实践

https://tech.meituan.com/recommend_dnn.html

	美团“猜你喜欢”场景接入了包括美食、酒店、旅游、外卖、民宿、交通等多种业务，这些业务各自有着丰富的内涵和特点，同时各业务的供给、需求与天气、时间、地理位置等条件交织，构成了O2O生活服务场景下特有的多样性和复杂性，这就给如何更高效地组织排序结果提出了更高的要求。构造更全面的特征、更准确高效地利用样本一直是我们优化的重点方向。

##### 特征种类

- User特征：用户年龄，性别，婚否，有无孩子等
- Item特征：价格，折扣，品类和品牌相关特征，短期和长期统计类特征等
- Context特征：天气，时间，地理位置，温度等
- 用户行为：用户点击Item序列，下单Item序列等

#### 3. 深度学习在文本领域的应用

https://tech.meituan.com/deep_learning_doc.html

文本领域大致可分为4个维度：词、句子、篇章、系统级应用。

- 词。分词方面，从最经典的前后向匹配到条件随机场（Conditional Random Field，CRF）序列标注，到现在Bi-LSTM+CRF模型，已经不需要设计特征，从字粒度就能做到最好的序列标注效果，并且可以推广到文本中序列标注问题上，比如词性标注和专门识别等。
- 句子。Parser方面，除词粒度介绍的深度学习序列标注外，还可以使用深度学习模型改善Shift-Reduce中间分类判断效果；句子生成方面，可以通过序列到序列（Seq2Seq）模型训练自动的句子生成器，可用于闲聊或者句子改写等场景。
- 篇章。情感分析方面，可以使用卷积神经网络对输入文本直接建模预测情感标签；阅读理解方面，可以设计具有记忆功能的循环神经网络来做阅读理解，这个也是近年非常热的研究问题。
- 系统级应用。信息检索方面，把深度学习技术用在文本匹配做相似度计算，可以通过BOW、卷积神经网络或循环神经网络表示再学习匹配关系（如DSSM系列），还有使用DNN做排序模型（如Google的Wide & Deep等，后面会重点介绍）；机器翻译方面，源于Seq2Seq模型到Stack-LSTM + Attention等多层LSTM网络，使得基于词的统计机器翻译模型已经被基于神经网络的翻译模型超越，并且已经应用到产品中，比如谷歌翻译、百度翻译、有道翻译等；智能交互方面，在做闲聊、对话、问答等系统时深度学习在分类、状态管理（如深度强化学习）、回复生成等环节都有很好的应用。

1. 基于深度学习的文本匹配

> 文本匹配在很多领域都有用到，尤其是信息检索相关场景，比如搜索的Query和Doc、广告中Query-Ad、搜索Suggestion中Query前缀和Query（见图1）、关键词推荐中Query和Query、文档去重时Doc和Doc等

#### 4. 