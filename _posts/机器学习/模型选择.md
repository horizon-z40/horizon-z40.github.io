#### 1. 赤池信息量(akaike information criterion,AIC)

建立在熵的概念上，提供了权衡估计模型复杂度和拟合数据优良性的标准。
$$
AIC = -2ln(L)+2k
$$
当在两个模型之间存在着相当大的差异时，这个差异出现于上式第一项（似然函数项），而当第二项不出现显著性差异时，第二项起作用，从而参数个数少的模型是好的模型。目标是选取AIC最小的模型，AIC不仅要提高模型拟合度（极大似然），而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。

让$N$ 为观察数，RSS为剩余平方和，那么AIC变为：
$$
AIC=Nln(RSS/N)+2k
$$


#### 2. 贝叶斯信息量（bayesian information criterion,BIC）

$$
BIC = -2ln(L)+ln(n)*k
$$

$kln(n)​$惩罚项在维数过大且训练样本数据相对较少的情况下，可以有效避免出现维度灾难现象。

#### 3. Hannan-quinn Criterion, HQ准则

$$
HQ=-2ln(L)+ln(ln(n))*k
$$

其中$L$是在该模型下的最大似然，$n$是数据数量，$k$是模型的变量个数。



https://esl.hohoweiya.xyz/07%20Model%20Assessment%20and%20Selection/7.7%20The%20Bayesian%20Approach%20and%20BIC/index.html